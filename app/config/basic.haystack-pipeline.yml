version: 1.14.0

components:

- name: DocumentStore
  type: FAISSDocumentStore
  #params:
  #  sql_url: sqlite:///indeces/faiss_document_store-TriviaQA-Flat.db
  #  embedding_dim: 768
  #  faiss_index_factory_str: Flat 
    # See index discussion: https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index
  #  index: natural_questions_docs  # make sure these align with additional_data in config
    # Note: Use `cosine` if using Sentence-Transformers, e.g. S-BERT
  #  similarity: dot_product  
  # uncomment this if NOT resetting ds
  params: 
    faiss_index_path: 'indeces/faiss_index-TriviaQA-wiki-nbpreprocessed-sbert-Flat.faiss'
    faiss_config_path: 'indeces/faiss_index-TriviaQA-wiki-nbpreprocessed-sbert-Flat.json'

- name: ESDocumentStore
  type: ElasticsearchDocumentStore
  params:
    embedding_field: emb
    excluded_meta_data:
    - emb
    index: eval_document  # TODO: change
    label_index: label  # TODO: change

#- name: Preprocessor  # do not change name
#  type: PreProcessor
#  params:
#    split_by: word
#    split_length: 200
#    split_overlap: 0
#    split_respect_sentence_boundary: False
#    clean_empty_lines: False
#    clean_whitespace: False
#
- name: Retriever  # do not change name
  type: EmbeddingRetriever
  # EmbeddingRetriever
  # DensePassageRetriever 
  params:
    embedding_model: sentence-transformers/multi-qa-mpnet-base-dot-v1
    # facebook/contriever-msmarco
    # sentence-transformers/all-MiniLM-L6-v2
    document_store: DocumentStore
    top_k: 20
    #batch_size: 16

- name: SparseRetriever
  type: BM25Retriever
  params: 
    document_store: ESDocumentStore
    top_k: 3

- name: Ranker
  type: SentenceTransformersRanker
  params: 
    model_name_or_path: cross-encoder/ms-marco-MiniLM-L-4-v2
    # cross-encoder/ms-marco-MiniLM-L-4-v2
    # cross-encoder/ms-marco-MiniLM-L-12-v2
    top_k: 1

- name: Reader
  type: TransformersReader
  params: # try this one later #
    model_name_or_path: google/bigbird-base-trivia-itc
    # deepset/roberta-base-squad2 
    # deepset/deberta-v3-base-squad2 
    # deepset/minilm-uncased-squad2
    # nlpconnect/roberta-base-squad2-nq
    # remunds/MiniLM_NaturalQuestions
    # AsmaAwad/distilbert-base-uncased-NaturalQuestions
    # FabianWillner/bert-base-uncased-finetuned-triviaqa
    return_no_answers: True
    top_k: 5
    #batch_size: 50
    
- name: FinalEvidenceFusion
  type: FinalEvidenceFusionNode
  params:
    reader_score_weight: 1.0
    retriever_score_weight: 0.2
    top_k: 3

pipelines:
- name: query_pipeline  
  nodes:
  - inputs:
    - Query
    name: Retriever
  - inputs:
    - Retriever
    name: Reader
    
- name: basic_ranker_pipeline  
  nodes:
  - inputs:
    - Query
    name: Retriever
  - inputs:
    - Retriever
    name: Ranker
  - inputs:
    - Ranker
    name: Reader
    
- name: sparse_query_pipeline
  nodes:
  - inputs:
    - Query
    name: SparseRetriever
  - inputs:
    - SparseRetriever
    name: Reader

#- name: hybrid_pipeline
#  nodes: 
#  - inputs:
#    - Query
#    name: SparseRetriever
#  - inputs: 
#    - Query
#    name: Retriever  # dense
#  - inputs:
#    - Retriever
#    name: Reader

#- name: fef_pipeline  
#  nodes:
#  - inputs:
#    - Query
#    name: Retriever
#  - inputs:
#    - Retriever
#    name: Reader
#  - inputs:
#    - Retriever
#    name: Ranker
#  - inputs:
#    - Reader
#    - Ranker
#    name: FinalEvidenceFusion
#  
- name: fef_large_pipeline  
  nodes:
  - inputs:
    - Query
    name: Retriever
  - inputs:
    - Retriever
    name: Ranker
  - inputs:
    - Ranker
    name: Reader
  - inputs:
    - Reader
    - Ranker
    name: FinalEvidenceFusion
    
